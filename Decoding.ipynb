{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o0rB1SvFOevmrGFezFUuaTVqPrXqvF7H",
      "authorship_tag": "ABX9TyP9zIklVRGZ5u2R1RTdmCsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerminkhalil/nerminkhalil/blob/main/Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hMHG4rA063j",
        "outputId": "ff3c2996-0c48-4742-d58c-be3900843269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_5rel.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_8_edu.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_3_ind.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_15_geo.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_9_ab.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_4_eth.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_2_mob.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_14_shl.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_13_hou.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_6_lang.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_12_fam.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_7_imgcit.csv\n",
            "✅ Saved: /content/decoded_output/decoded_data_donnees_2021_10_com.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# === Set up paths ===\n",
        "data_folder = \"/content\"\n",
        "output_folder = os.path.join(data_folder, \"decoded_output\")\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# === Step 1: Load decoders for all variables from each dictionary file ===\n",
        "decoder_maps = {}\n",
        "column_titles = {}\n",
        "\n",
        "for decoder_file in glob.glob(os.path.join(data_folder, \"*_output.csv\")):\n",
        "    df_decoder = pd.read_csv(decoder_file)\n",
        "\n",
        "    if df_decoder.empty or \"Mnemonic\" not in df_decoder.columns:\n",
        "        continue\n",
        "\n",
        "    grouped = df_decoder.groupby(\"Mnemonic\")\n",
        "    for mnemonic, group in grouped:\n",
        "        group = group.drop_duplicates(subset=\"Code\")\n",
        "        decoder_maps[mnemonic] = dict(zip(group[\"Code\"], group[\"Value\"]))\n",
        "        column_titles[mnemonic] = group[\"Title\"].iloc[0]\n",
        "\n",
        "# === Step 2: Process each data file and decode all applicable columns ===\n",
        "for data_file in glob.glob(os.path.join(data_folder, \"data_donnees_2021_*.csv\")):\n",
        "    df = pd.read_csv(data_file)\n",
        "    decoded_df = df.copy()\n",
        "\n",
        "    renamed_columns = {}\n",
        "    for col in df.columns:\n",
        "        if col in decoder_maps:\n",
        "            decoded_df[col] = df[col].map(decoder_maps[col])\n",
        "            renamed_columns[col] = column_titles.get(col, col)\n",
        "\n",
        "    decoded_df.rename(columns=renamed_columns, inplace=True)\n",
        "\n",
        "    output_name = \"decoded_\" + os.path.basename(data_file)\n",
        "    output_path = os.path.join(output_folder, output_name)\n",
        "    decoded_df.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Saved: {output_path}\")\n"
      ]
    }
  ]
}